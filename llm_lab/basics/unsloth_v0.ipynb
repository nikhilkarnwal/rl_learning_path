{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "a7d0df3c",
      "metadata": {
        "id": "a7d0df3c"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import os, re\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth  # Do this in local & cloud setups\n",
        "else:\n",
        "    import torch; v = re.match(r'[\\d]{1,}\\.[\\d]{1,}', str(torch.__version__)).group(0)\n",
        "    xformers = 'xformers==' + {'2.9':'0.0.33.post1','2.8':'0.0.32.post2'}.get(v, \"0.0.33.post1\")\n",
        "    !pip install sentencepiece protobuf \"datasets==4.3.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
        "    !pip install --no-deps unsloth_zoo bitsandbytes accelerate {xformers} peft trl triton unsloth\n",
        "!pip install transformers==4.56.2 && pip install --no-deps trl==0.22.2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsloth"
      ],
      "metadata": {
        "id": "ps5OE-2dnuCp"
      },
      "id": "ps5OE-2dnuCp"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "f64e1495",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f64e1495",
        "outputId": "bff22e8f-ff83-4e56-9093-c6968a0f17f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth 2026.1.4: Fast Gemma3 patching. Transformers: 4.56.2.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.9.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.5.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.33.post1. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "Unsloth: Gemma3 does not support SDPA - switching to fast eager.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastSentenceTransformer\n",
        "\n",
        "fourbit_models = [\n",
        "    \"unsloth/all-MiniLM-L6-v2\",\n",
        "    \"unsloth/embeddinggemma-300m\",\n",
        "    \"unsloth/Qwen3-Embedding-4B\",\n",
        "    \"unsloth/Qwen3-Embedding-0.6B\",\n",
        "    \"unsloth/all-mpnet-base-v2\",\n",
        "    \"unsloth/gte-modernbert-base\",\n",
        "    \"unsloth/bge-m3\"\n",
        "\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model = FastSentenceTransformer.from_pretrained(\n",
        "    model_name = \"unsloth/embeddinggemma-300m\",\n",
        "    max_seq_length = 1024,   # Choose any for long context!\n",
        "    full_finetuning = False, # [NEW!] We have full finetuning now!\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKN1I5GBodk9",
        "outputId": "1f9f907e-4cd8-4d8b-d27d-a52fcf980fea"
      },
      "id": "JKN1I5GBodk9",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SentenceTransformer(\n",
            "  (0): Transformer({'max_seq_length': 1024, 'do_lower_case': False, 'architecture': 'Gemma3TextModel'})\n",
            "  (1): Pooling({'word_embedding_dimension': 768, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
            "  (2): Dense({'in_features': 768, 'out_features': 3072, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
            "  (3): Dense({'in_features': 3072, 'out_features': 768, 'bias': False, 'activation_function': 'torch.nn.modules.linear.Identity'})\n",
            "  (4): Normalize()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7d81fdc9",
        "outputId": "dc2d8d56-dffe-47f2-9203-f03949cbd7af"
      },
      "source": [
        "print(model[0].auto_model)"
      ],
      "id": "7d81fdc9",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gemma3TextModel(\n",
            "  (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 768, padding_idx=0)\n",
            "  (layers): ModuleList(\n",
            "    (0-23): 24 x Gemma3DecoderLayer(\n",
            "      (self_attn): Gemma3Attention(\n",
            "        (q_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (k_proj): Linear(in_features=768, out_features=256, bias=False)\n",
            "        (v_proj): Linear(in_features=768, out_features=256, bias=False)\n",
            "        (o_proj): Linear(in_features=768, out_features=768, bias=False)\n",
            "        (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "        (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "      )\n",
            "      (mlp): Gemma3MLP(\n",
            "        (gate_proj): Linear(in_features=768, out_features=1152, bias=False)\n",
            "        (up_proj): Linear(in_features=768, out_features=1152, bias=False)\n",
            "        (down_proj): Linear(in_features=1152, out_features=768, bias=False)\n",
            "        (act_fn): PytorchGELUTanh()\n",
            "      )\n",
            "      (input_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "      (post_attention_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "      (pre_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "      (post_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "    )\n",
            "  )\n",
            "  (norm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "  (rotary_emb): Gemma3RotaryEmbedding()\n",
            "  (rotary_emb_local): Gemma3RotaryEmbedding()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50ad3d2e"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Q&A\n",
        "The `unsloth/embeddinggemma-300m` model processes an input sentence by first tokenizing it and converting tokens into initial 768-dimensional embeddings using the `Gemma3TextScaledWordEmbedding` layer. These embeddings are then refined through 24 `Gemma3DecoderLayer` blocks, which include `Gemma3Attention` for contextual understanding, `Gemma3MLP` for non-linear transformations, `Gemma3RMSNorm` for stabilization, and `Gemma3RotaryEmbedding` for positional information. The sequence of token embeddings is then condensed into a single 768-dimensional sentence embedding by a `Pooling` layer using mean pooling. This pooled embedding undergoes further linear transformations by two `Dense` layers, expanding to 3072 dimensions and then contracting back to 768 dimensions. Finally, a `Normalize` layer applies L2 normalization to the embedding. The final output embedding is a 768-dimensional, L2-normalized vector that represents the semantic meaning of the entire input sentence, optimized for robust similarity comparisons.\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **Input Embedding:** The `Gemma3TextScaledWordEmbedding` layer converts tokens into initial 768-dimensional embeddings, supporting a vocabulary of 262,144 unique tokens.\n",
        "*   **Transformer Architecture:** The model employs 24 `Gemma3DecoderLayer` blocks for processing the sequence.\n",
        "    *   **`Gemma3Attention`:** Uses Query, Key, and Value projections where Query projection maps 768 features to 768, while Key and Value projections map 768 features to 256. `Gemma3RMSNorm` (256-dim) is applied to Query and Key projections.\n",
        "    *   **`Gemma3MLP`:** Expands the feature space from 768 to 1152 dimensions (via `gate_proj` and `up_proj`) and then contracts it back to 768 dimensions (via `down_proj`), incorporating `PytorchGELUTanh()` as an activation function.\n",
        "    *   **`Gemma3RMSNorm`:** Multiple 768-dimensional `Gemma3RMSNorm` layers are strategically placed within `Gemma3DecoderLayer` blocks to stabilize training.\n",
        "    *   **`Gemma3RotaryEmbedding`:** Injects positional information into the attention mechanism using rotation matrices, aiding in understanding sequential order.\n",
        "*   **Pooling:** The `Pooling` layer utilizes `pooling_mode_mean_tokens` to calculate the element-wise average of all token embeddings, resulting in a single 768-dimensional sentence embedding.\n",
        "*   **Dense Layers:** Two `Dense` layers refine the pooled embedding:\n",
        "    *   The first expands the 768-dimensional input to 3072 dimensions.\n",
        "    *   The second contracts the 3072-dimensional output back to 768 dimensions. Both layers perform purely linear transformations (`bias: False`, `activation_function: 'torch.nn.modules.linear.Identity'`).\n",
        "*   **Normalization:** The final `Normalize` layer applies L2 normalization to the 768-dimensional embedding, scaling it to a unit length. This is critical for ensuring that similarity measures (like cosine similarity) are based purely on vector direction, improving performance in tasks like similarity search.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The architecture's design, particularly the final L2 normalization, indicates a strong optimization for applications requiring robust vector similarity comparisons, such as semantic search, retrieval, and clustering.\n",
        "*   The use of `Identity` activation in the `Dense` layers suggests that these stages primarily focus on linear projection and dimensionality manipulation to refine the embedding space, rather than introducing additional non-linear complexities after the transformer layers.\n"
      ],
      "id": "50ad3d2e"
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now add LoRA adapters so we only need to update a small amount of parameters!"
      ],
      "metadata": {
        "id": "A74OAxgVztIS"
      },
      "id": "A74OAxgVztIS"
    },
    {
      "cell_type": "code",
      "source": [
        "model = FastSentenceTransformer.get_peft_model(\n",
        "    model,\n",
        "    r = 32, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 64,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        "    task_type = \"FEATURE_EXTRACTION\"\n",
        ")"
      ],
      "metadata": {
        "id": "Cl3BE7MmzmmB",
        "outputId": "272005eb-2558-473f-c077-8eb2e9af78e1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Cl3BE7MmzmmB",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `model.base_model.model` require gradients\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model[0].auto_model)"
      ],
      "metadata": {
        "id": "jOUNEjqtz9w-",
        "outputId": "6792a6b8-6700-4a04-e1b0-88388ea7027a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "jOUNEjqtz9w-",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PeftModelForFeatureExtraction(\n",
            "  (base_model): LoraModel(\n",
            "    (model): Gemma3TextModel(\n",
            "      (embed_tokens): Gemma3TextScaledWordEmbedding(262144, 768, padding_idx=0)\n",
            "      (layers): ModuleList(\n",
            "        (0-23): 24 x Gemma3DecoderLayer(\n",
            "          (self_attn): Gemma3Attention(\n",
            "            (q_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=768, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (k_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=256, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=256, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (v_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=256, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=256, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (o_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=768, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=768, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (q_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "            (k_norm): Gemma3RMSNorm((256,), eps=1e-06)\n",
            "          )\n",
            "          (mlp): Gemma3MLP(\n",
            "            (gate_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=1152, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=1152, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (up_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=768, out_features=1152, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=768, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=1152, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (down_proj): lora.Linear(\n",
            "              (base_layer): Linear(in_features=1152, out_features=768, bias=False)\n",
            "              (lora_dropout): ModuleDict(\n",
            "                (default): Identity()\n",
            "              )\n",
            "              (lora_A): ModuleDict(\n",
            "                (default): Linear(in_features=1152, out_features=32, bias=False)\n",
            "              )\n",
            "              (lora_B): ModuleDict(\n",
            "                (default): Linear(in_features=32, out_features=768, bias=False)\n",
            "              )\n",
            "              (lora_embedding_A): ParameterDict()\n",
            "              (lora_embedding_B): ParameterDict()\n",
            "              (lora_magnitude_vector): ModuleDict()\n",
            "            )\n",
            "            (act_fn): PytorchGELUTanh()\n",
            "          )\n",
            "          (input_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "          (post_attention_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "          (pre_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "          (post_feedforward_layernorm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "        )\n",
            "      )\n",
            "      (norm): Gemma3RMSNorm((768,), eps=1e-06)\n",
            "      (rotary_emb): Gemma3RotaryEmbedding()\n",
            "      (rotary_emb_local): Gemma3RotaryEmbedding()\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}